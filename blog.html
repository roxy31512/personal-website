<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Blog | Roxana Akhmetova</title>
  <meta name="description" content="Thoughts on AI policy, governance, and emerging technology">
  <meta name="keywords" content="AI policy, AI governance, technology policy, artificial intelligence">
  <meta name="author" content="Roxana Akhmetova">

  <script src="https://cdn.tailwindcss.com"></script>
  <script>
    tailwind.config = {
      theme: {
        extend: {
          colors: {
            dark: '#1a1a1a',
            mid: '#4d4d4d',
            light: '#f7f7f8',
            oxford: '#002147',
            'oxford-100': '#e6eefb',
            'oxford-600': '#234e85'
          }
        }
      }
    }
  </script>

  <link rel="stylesheet" href="style.css">

  <style>
    html, body {
      background-color: #1a1a1a !important;
      min-height: 100%;
    }
    
    main {
      margin-top: 100px;
      max-width: 1200px;
      padding: 0 40px;
      margin-left: auto;
      margin-right: auto;
      margin-bottom: 60px;
    }
    
    h1 {
      font-size: 2.5rem !important;
      margin-bottom: 24px !important;
      color: #ffffff !important;
      font-weight: 600 !important;
      -webkit-text-fill-color: #ffffff !important;
      text-shadow: none !important;
      opacity: 1 !important;
      border-bottom: 3px solid #e6eefb;
      display: inline-block;
      padding-bottom: 8px;
    }

    .page-subtitle {
      color: #9fc0ff;
      font-size: 1.1rem;
      margin-bottom: 50px;
      font-weight: 400;
    }

    /* Blog Preview Card Styles */
    .blog-preview-card {
      background: rgba(255,255,255,0.03);
      border-left: 3px solid #9fc0ff;
      padding: 30px;
      margin-bottom: 30px;
      border-radius: 8px;
      transition: all 0.3s ease;
      text-decoration: none;
      display: block;
    }

    .blog-preview-card:hover {
      background: rgba(255,255,255,0.05);
      transform: translateX(5px);
      border-left-color: #ffffff;
    }

    .blog-meta {
      display: flex;
      align-items: center;
      gap: 12px;
      margin-bottom: 15px;
      font-size: 0.9rem;
      color: #9fc0ff;
      font-weight: 500;
    }

    .blog-meta-separator {
      color: #4d4d4d;
    }

    .blog-category {
      text-transform: uppercase;
      letter-spacing: 0.5px;
      font-size: 0.85rem;
    }

    .blog-preview-title {
      color: #ffffff;
      font-size: 1.5rem;
      font-weight: 600;
      margin-bottom: 15px;
      line-height: 1.3;
    }

    .blog-preview-excerpt {
      color: #d8e1eb;
      font-size: 1.05rem;
      line-height: 1.7;
      margin-bottom: 20px;
    }

    .read-more {
      color: #9fc0ff;
      font-weight: 600;
      font-size: 0.95rem;
      display: inline-flex;
      align-items: center;
      gap: 8px;
      transition: all 0.3s ease;
      margin-bottom: 15px;
    }

    .read-more:hover {
      color: #ffffff;
      gap: 12px;
    }

    .blog-preview-tags {
      display: flex;
      gap: 10px;
      flex-wrap: wrap;
      padding-top: 15px;
      border-top: 1px solid rgba(159, 192, 255, 0.1);
    }

    .blog-tag {
      background: rgba(159, 192, 255, 0.1);
      color: #9fc0ff;
      padding: 5px 12px;
      border-radius: 15px;
      font-size: 0.85rem;
      font-weight: 500;
    }

    @media (max-width: 768px) {
      main {
        padding: 0 20px;
      }
      
      h1 {
        font-size: 2em !important;
      }
      
      .blog-preview-card {
        padding: 20px;
      }
      
      .word-cloud-container {
        padding: 20px;
      }
      
      .word-cloud-item.size-1 { font-size: 1.8rem; }
      .word-cloud-item.size-2 { font-size: 1.5rem; }
      .word-cloud-item.size-3 { font-size: 1.3rem; }
      .word-cloud-item.size-4 { font-size: 1.1rem; }
      .word-cloud-item.size-5 { font-size: 0.95rem; }
    }
  </style>
</head>

<body>
  <custom-navbar></custom-navbar>

  <main>
    <h1>Blog</h1>
    <div class="page-subtitle">Thoughts on AI policy, governance, and emerging technology</div>

    <!-- Blog Preview Cards -->
    
    <!-- Post 1 -->
    <a href="/blog/us-china-agi-relations.html" class="blog-preview-card">
      <div class="blog-meta">
        <span>November 2025</span>
        <span class="blog-meta-separator">•</span>
        <span class="blog-category">Diplomatic Policy</span>
      </div>
      <h2 class="blog-preview-title">US-China AGI Relations and Diplomatic Interventions (2025-2030)</h2>
      <p class="blog-preview-excerpt">
        Over the next 1-5 years, I expect that the U.S.-China AGI relations will escalate because of three dynamics: (1) accelerated development of frontier AI, (2) China may increase its technical independence from U.S. export controls by producing domestic chips, (3) as AI systems become more autonomous they will become more opaque and harder to control. The main risk in US-China relations is unintentional escalation...
      </p>
      <span class="read-more">Read More →</span>
      <div class="blog-preview-tags">
        <span class="blog-tag">US-China Relations</span>
        <span class="blog-tag">AGI</span>
        <span class="blog-tag">Diplomatic Policy</span>
        <span class="blog-tag">AI Safety</span>
      </div>
    </a>

    <!-- Post 2 -->
    <a href="/blog/ai-chip-export-controls.html" class="blog-preview-card">
      <div class="blog-meta">
        <span>November 2025</span>
        <span class="blog-meta-separator">•</span>
        <span class="blog-category">Export Controls</span>
      </div>
      <h2 class="blog-preview-title">Strengthening AI Chip Export Controls: Recommendations for Department of Commerce</h2>
      <p class="blog-preview-excerpt">
        I recommend BIS adopt two interventions to close enforcement gaps: (1) tiered export licensing that is based on verification requirements, and (2) an embedded technical assessment capability at NIST AISI. BIS export AI chips controls use three mechanisms: performance-based thresholds which restrict advanced logic chips and high-bandwidth memory...
      </p>
      <span class="read-more">Read More →</span>
      <div class="blog-preview-tags">
        <span class="blog-tag">Export Controls</span>
        <span class="blog-tag">AI Chips</span>
        <span class="blog-tag">Policy Memo</span>
        <span class="blog-tag">BIS</span>
      </div>
    </a>

    <!-- Post 3 -->
    <a href="/blog/nvidia-b30a-forecast.html" class="blog-preview-card">
      <div class="blog-meta">
        <span>November 2025</span>
        <span class="blog-meta-separator">•</span>
        <span class="blog-category">Forecasting</span>
      </div>
      <h2 class="blog-preview-title">Will Chinese Companies Import Over 100K NVIDIA B30A Chips by End of 2026?</h2>
      <p class="blog-preview-excerpt">
        Chinese authorities have recently signalled a disinterest in importing NVIDIA H20 chips, mainly on security grounds. The NVIDIA B30A would be a more powerful chip than the H20, and the US government may allow B30As to be exported to China. My prediction is that there's a 35-45% chance Chinese companies import >100K B30As by end of 2026...
      </p>
      <span class="read-more">Read More →</span>
      <div class="blog-preview-tags">
        <span class="blog-tag">Export Controls</span>
        <span class="blog-tag">China</span>
        <span class="blog-tag">NVIDIA</span>
        <span class="blog-tag">Forecasting</span>
      </div>
    </a>

    <!-- Post 4 -->
    <a href="/blog/thermal-signature-monitoring.html" class="blog-preview-card">
      <div class="blog-meta">
        <span>November 2025</span>
        <span class="blog-meta-separator">•</span>
        <span class="blog-category">Technical Solutions</span>
      </div>
      <h2 class="blog-preview-title">Thermal Signature Monitoring: A Cost-Effective Approach to GPU Verification</h2>
      <p class="blog-preview-excerpt">
        How can the Bureau of Industry and Security (BIS) verify, with reasonably high confidence, that GPUs in a given data center have not been physically transported? For already-installed GPUs that cannot rely on technical location verification, I propose a cheap, scalable solution using thermal signature monitoring...
      </p>
      <span class="read-more">Read More →</span>
      <div class="blog-preview-tags">
        <span class="blog-tag">Export Controls</span>
        <span class="blog-tag">Verification</span>
        <span class="blog-tag">Technical Solutions</span>
        <span class="blog-tag">BIS</span>
      </div>
    </a>

    <!-- Post 5 -->
    <a href="/blog/ai-agents-export-control.html" class="blog-preview-card">
      <div class="blog-meta">
        <span>November 2025</span>
        <span class="blog-meta-separator">•</span>
        <span class="blog-category">Risk Analysis</span>
      </div>
      <h2 class="blog-preview-title">Two Critical Failure Modes of AI Agents in Export Control Monitoring</h2>
      <p class="blog-preview-excerpt">
        If BIS deployed AI agents to continuously monitor shipping manifests, customs declarations, corporate filings, and other documents to detect export control violations, the system could fail badly or create new problems in distinct ways. Failure 1: Adversarial Prompt Tampering. Adversaries could tamper with AI prompts by embedding adversarial content...
      </p>
      <span class="read-more">Read More →</span>
      <div class="blog-preview-tags">
        <span class="blog-tag">AI Agents</span>
        <span class="blog-tag">Export Controls</span>
        <span class="blog-tag">Risk Analysis</span>
        <span class="blog-tag">BIS</span>
      </div>
    </a>

    <!-- Post 6 -->
    <a href="/blog/international-ai-cooperation.html" class="blog-preview-card">
      <div class="blog-meta">
        <span>October 2025</span>
        <span class="blog-meta-separator">•</span>
        <span class="blog-category">Governance</span>
      </div>
      <h2 class="blog-preview-title">The Current State of International AI Safety Cooperation</h2>
      <p class="blog-preview-excerpt">
        Over the past 5 years, international cooperation on AI safety has expanded significantly, with several overlapping mechanisms that aimed to bring governments, corporations, and civil society organisations together on the same page about how to safely build and deploy AI. Despite the growing concern about risks from frontier AI...
      </p>
      <span class="read-more">Read More →</span>
      <div class="blog-preview-tags">
        <span class="blog-tag">International Cooperation</span>
        <span class="blog-tag">AI Safety</span>
        <span class="blog-tag">Governance</span>
        <span class="blog-tag">Diplomacy</span>
      </div>
    </a>

    <!-- Post 7 -->
    <a href="/blog/quarterly-evaluation-sprint.html" class="blog-preview-card">
      <div class="blog-meta">
        <span>October 2025</span>
        <span class="blog-meta-separator">•</span>
        <span class="blog-category">Policy Framework</span>
      </div>
      <h2 class="blog-preview-title">A Quarterly Evaluation Sprint Program for Frontier AI Safety</h2>
      <p class="blog-preview-excerpt">
        Small, like-minded countries—the UK, Japan, Canada, and Singapore—could build trust and shared capacity on frontier AI safety through a modest but practical cooperative step. Rather than duplicating the UN or G7, I propose a quarterly evaluation sprint program. These four countries already have established AI safety institutes...
      </p>
      <span class="read-more">Read More →</span>
      <div class="blog-preview-tags">
        <span class="blog-tag">International Cooperation</span>
        <span class="blog-tag">AI Safety</span>
        <span class="blog-tag">Model Evaluation</span>
        <span class="blog-tag">Policy Framework</span>
      </div>
    </a>

    <!-- Post 8 -->
    <a href="/blog/capability-forecasting-asymmetry.html" class="blog-preview-card">
      <div class="blog-meta">
        <span>October 2025</span>
        <span class="blog-meta-separator">•</span>
        <span class="blog-category">Transparency</span>
      </div>
      <h2 class="blog-preview-title">The Biggest Information Asymmetry in AI: Proprietary Capability Forecasting Models</h2>
      <p class="blog-preview-excerpt">
        I think the biggest information asymmetry in the AI debate is that capability forecasting models remain proprietary to labs, specifically, their internal predictions of when dangerous capabilities will emerge at scale. Other asymmetries exist, such as deployment data, safety research findings, or incident reports, but capability models shape predictions...
      </p>
      <span class="read-more">Read More →</span>
      <div class="blog-preview-tags">
        <span class="blog-tag">AI Governance</span>
        <span class="blog-tag">Transparency</span>
        <span class="blog-tag">Information Asymmetry</span>
        <span class="blog-tag">Policy</span>
      </div>
    </a>

    <!-- Post 9 -->
    <a href="/blog/addressing-information-gaps.html" class="blog-preview-card">
      <div class="blog-meta">
        <span>October 2025</span>
        <span class="blog-meta-separator">•</span>
        <span class="blog-category">Policy Strategy</span>
      </div>
      <h2 class="blog-preview-title">Three Strategies to Address AI Information Gaps</h2>
      <p class="blog-preview-excerpt">
        The core challenge is building institutional capacity to enforce and process the information. I'd prioritise 3 strategies: (1) Mandatory Disclosure - Labs above a certain compute threshold should submit capability models to regulators before major training runs. (2) Liability-Based Economic Pressure - Develop safe harbors where labs that share capability models...
      </p>
      <span class="read-more">Read More →</span>
      <div class="blog-preview-tags">
        <span class="blog-tag">AI Governance</span>
        <span class="blog-tag">Policy Strategy</span>
        <span class="blog-tag">Regulation</span>
        <span class="blog-tag">Transparency</span>
      </div>
    </a>

    <!-- Post 10 -->
    <a href="/blog/power-concentration.html" class="blog-preview-card">
      <div class="blog-meta">
        <span>October 2025</span>
        <span class="blog-meta-separator">•</span>
        <span class="blog-category">Democracy</span>
      </div>
      <h2 class="blog-preview-title">AI-Enabled Power Concentration: Comparing Risks in Authoritarian Regimes and Democracies</h2>
      <p class="blog-preview-excerpt">
        Both authoritarian regimes and democracies face risks from AI-enabled power concentration, though these threats manifest in different ways. In authoritarian systems, AI doesn't just make transitions messier, but it also makes them more likely to be violent. After a change in leadership, either via a coup or some other method...
      </p>
      <span class="read-more">Read More →</span>
      <div class="blog-preview-tags">
        <span class="blog-tag">AI Governance</span>
        <span class="blog-tag">Democracy</span>
        <span class="blog-tag">Authoritarianism</span>
        <span class="blog-tag">Power Concentration</span>
      </div>
    </a>

    <!-- Post 11 -->
    <a href="/blog/open-problems-ai-risk.html" class="blog-preview-card">
      <div class="blog-meta">
        <span>September 2025</span>
        <span class="blog-meta-separator">•</span>
        <span class="blog-category">Risk Management</span>
      </div>
      <h2 class="blog-preview-title">Five Urgent Open Problems in Frontier AI Risk Management</h2>
      <p class="blog-preview-excerpt">
        With frontier AI, capability jumps will likely be unpredictable and non-linear and often invisible until they cross some deployment threshold. So the detection lag needs to be shorter than capability emergence timescales, but right now it's inverted. We need metrics that can signal dangerous capability before it actually happens...
      </p>
      <span class="read-more">Read More →</span>
      <div class="blog-preview-tags">
        <span class="blog-tag">AI Risk</span>
        <span class="blog-tag">Frontier AI</span>
        <span class="blog-tag">Risk Management</span>
        <span class="blog-tag">AI Safety</span>
      </div>
    </a>

    <!-- Post 12 -->
    <a href="/blog/hft-lessons.html" class="blog-preview-card">
      <div class="blog-meta">
        <span>September 2025</span>
        <span class="blog-meta-separator">•</span>
        <span class="blog-category">Case Study</span>
      </div>
      <h2 class="blog-preview-title">Lessons from High-Frequency Trading for AI Governance</h2>
      <p class="blog-preview-excerpt">
        I chose high-frequency trading as a case study. As algorithmic tools became more popular between 2000s - 2010s, the finance world adopted autonomous trading tools (algorithmic decision rules and statistical models) into their trading systems to make and cancel orders at microsecond to millisecond timescales...
      </p>
      <span class="read-more">Read More →</span>
      <div class="blog-preview-tags">
        <span class="blog-tag">Technology Governance</span>
        <span class="blog-tag">Financial Regulation</span>
        <span class="blog-tag">Case Study</span>
        <span class="blog-tag">Policy Lessons</span>
      </div>
    </a>

    <!-- Post 13 -->
    <a href="/blog/children-chatbots.html" class="blog-preview-card">
      <div class="blog-meta">
        <span>September 2025</span>
        <span class="blog-meta-separator">•</span>
        <span class="blog-category">AI Ethics</span>
      </div>
      <h2 class="blog-preview-title">Children and AI Chatbots: Weighing Concerns About Regulation</h2>
      <p class="blog-preview-excerpt">
        AI chatbots are now able to engage in natural, emotional conversations with people. They can also convincingly simulate the personalities of specific people and characters. It has been reported that growing numbers of children and teenagers are spending significant time interacting with these chatbots...
      </p>
      <span class="read-more">Read More →</span>
      <div class="blog-preview-tags">
        <span class="blog-tag">AI Ethics</span>
        <span class="blog-tag">Children</span>
        <span class="blog-tag">Chatbots</span>
        <span class="blog-tag">Regulation</span>
      </div>
    </a>

    <!-- Post 14 -->
    <a href="/blog/evaluating-evaluators.html" class="blog-preview-card">
      <div class="blog-meta">
        <span>September 2025</span>
        <span class="blog-meta-separator">•</span>
        <span class="blog-category">Audit</span>
      </div>
      <h2 class="blog-preview-title">Who Evaluates the Evaluators? Frameworks for Accreditation in Frontier AI Governance</h2>
      <p class="blog-preview-excerpt">
        A core challenge for accreditation is verifying an assessor's "independence from undue pressures", especially from the well-funded and influential AI developer being assessed. I propose a two-tiered system for ensuring and auditing this independence. Tier 1 includes pooled funding, revenue diversification, rotating networks...
      </p>
      <span class="read-more">Read More →</span>
      <div class="blog-preview-tags">
        <span class="blog-tag">Accreditation</span>
        <span class="blog-tag">AI Governance</span>
        <span class="blog-tag">Audit</span>
        <span class="blog-tag">Policy</span>
      </div>
    </a>

  </main>

  <custom-footer></custom-footer>
  <script src="https://roxanaakhmetova.com/components/navbar.js"></script>
  <script src="https://roxanaakhmetova.com/components/footer.js"></script>

  <script>
    document.addEventListener('selectstart', e => e.preventDefault());
    document.addEventListener('contextmenu', e => e.preventDefault());
    document.addEventListener('keydown', e => {
      if (
        (e.ctrlKey && (e.key === 'c' || e.key === 'x' || e.key === 's' || e.key === 'u')) ||
        (e.metaKey && (e.key === 'c' || e.key === 'x' || e.key === 's' || e.key === 'u')) ||
        (e.ctrlKey && e.shiftKey && e.key === 'I') ||
        (e.ctrlKey && e.shiftKey && e.key === 'J') ||
        (e.ctrlKey && e.key === 'p')
      ) {
        e.preventDefault();
      }
    });
    document.body.style.userSelect = 'none';
  </script>
</body>
</html>