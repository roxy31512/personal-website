<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>The Current State of International AI Safety Cooperation | Roxana Akhmetova</title>
  <meta name="description" content="The Current State of International AI Safety Cooperation" />
  <meta name="author" content="Roxana Akhmetova" />

  <script src="https://cdn.tailwindcss.com"></script>
  <script>
    tailwind.config = {
      theme: {
        extend: {
          colors: {
            dark: '#1a1a1a',
            mid: '#4d4d4d',
            light: '#f7f7f8',
            oxford: '#002147',
            'oxford-100': '#e6eefb',
            'oxford-600': '#234e85'
          }
        }
      }
    }
  </script>

  <link rel="stylesheet" href="/style.css" />

  <style>
    html, body {
      background-color: #1a1a1a !important;
      min-height: 100%;
      color: #ffffff;
    }

    main {
      margin-top: 100px;
      max-width: 900px;
      padding: 0 40px;
      margin-left: auto;
      margin-right: auto;
      margin-bottom: 80px;
    }

    h1 {
      font-size: 2.2rem !important;
      margin-bottom: 24px !important;
      color: #ffffff !important;
      font-weight: 600 !important;
      border-bottom: 3px solid #e6eefb;
      display: inline-block;
      padding-bottom: 8px;
    }

    .post-date {
      color: #9fc0ff;
      font-size: 0.95rem;
      margin-bottom: 30px;
      font-weight: 500;
    }

    .post-content p {
      color: #d8e1eb;
      font-size: 1.05rem;
      line-height: 1.8;
      margin-bottom: 20px;
      white-space: pre-wrap;
    }

    .blog-post-tags {
      display: flex;
      gap: 10px;
      flex-wrap: wrap;
      margin-top: 30px;
    }

    .blog-tag {
      background: rgba(159, 192, 255, 0.1);
      color: #9fc0ff;
      padding: 5px 12px;
      border-radius: 15px;
      font-size: 0.85rem;
      font-weight: 500;
    }

    a.back-link {
      display: inline-block;
      color: #9fc0ff;
      margin-bottom: 40px;
      font-weight: 600;
      transition: all 0.3s ease;
    }

    a.back-link:hover {
      color: #ffffff;
      transform: translateX(-4px);
    }

    @media (max-width: 768px) {
      main { padding: 0 20px; }
      h1 { font-size: 1.8rem !important; }
      .post-content p { font-size: 1rem; }
    }
  </style>
</head>

<body>
  <custom-navbar></custom-navbar>

  <main>
    <a href="/blog.html" class="back-link">&larr; Back to Blog</a>

    <h1>The Current State of International AI Safety Cooperation</h1>
    <div class="post-date">October 2025</div>

    <div class="post-content">
      <p>Over the past 5 years, international cooperation on AI safety has expanded significantly, with several overlapping mechanisms that aimed to bring governments, corporations, and civil society organisations together on the same page about how to safely build and deploy AI. Despite the growing concern about risks from frontier AI, leading corporations and governments are falling behind on ensuring that there are robust accountability, transparency, and fairness frameworks implemented.</p>

      <p>States organised a number of multilateral summits and talks in the past 5 years which brought together governments, labs, and civil society to discuss frontier AI risks (Bletchley Park 2023, Seoul 2024, Paris 2025, Delhi 2026). One success is the Bletchley 2023 produced the Bletchley Declaration which was signed by 28 countries, including the US and China. This was a rare consensus on existential risks. The Declaration also created AI Safety Institutes in the UK, US, Singapore, and Japan as national nodes for technical safety evaluation.</p>

      <p>But states aren't the only ones contributing to AI safety. The UN AI Advisory Body & High-Level AI Governance Process was developed and has become a key player. The Secretary-General's advisory body released recommendations in 2024 for global AI governance which pushed for creating an international scientific panel (IPCC-style) for AI risks. A General Assembly resolution in March 2024 focused on 'safe, secure and trustworthy AI' and was the first global consensus document.</p>

      <p>Despite this, there are signs of cooperation. For one, the US and the UK have strong signs of cooperation via their AI Safety Institutes. Both institutes share technical staff, collaborate on model evaluation frameworks, and coordinate approaches to capability testing. Their partnership functions partly because both countries share similar regulation approaches and neither sees the other as a strategic competitor in AI development. US and EU cooperation efforts may be less optimistic, in part due to how each approaches AI governance. America prioritises innovation and the European Union prioritises regulation-first frameworks. The EU AI Act is a very comprehensive regulatory model that influences global debates; however, it does not have strong enforcement mechanisms yet. In contrast, the US would unlikely to adopt a similar AI Act because of how structuring it may seem to US AI labs.</p>

      <p>Given Chinese and American dominance in frontier AI, their cooperation is under the most tension. Although there are some academic and informal dialogues between the two countries, government-level engagement is constrained by geopolitical tensions. There is a lot of tension around export controls on advanced chips and national security concerns. What drives this tension is the broader US-China rivalry over technological supremacy. Adding to it is that both sides don't know how far along the other is in the race toward AGI, and so both are accelerating their own domestic AI development. This is creating the race dynamic that makes international safety coordination necessary but challenging to achieve.</p>

      <p>One limitation is that one of the most visible forms of coordination which is on export controls of advanced chips doesn't prioritise safety over competition. The US has restricted exports of H100 and H200 GPUs to China and separately coordinated with the Netherlands and Japan to limit China's access to semiconductor manufacturing equipment. This fragments the global AI ecosystem. Experts argue that treating AI development as a national security competition while simultaneously trying to coordinate on safety thresholds is contradictory. Countries cannot verify each other's safety commitments when they view each other as adversaries who are racing toward strategic advantage.</p>
    </div>

    <div class="blog-post-tags">
      <span class="blog-tag">International Cooperation</span>
      <span class="blog-tag">AI Safety</span>
      <span class="blog-tag">Governance</span>
      <span class="blog-tag">Diplomacy</span>
    </div>
  </main>

  <custom-footer></custom-footer>
  <script src="/components/navbar.js"></script>
  <script src="/components/footer.js"></script>

<script>
  document.addEventListener('selectstart', e => e.preventDefault());
  document.addEventListener('contextmenu', e => e.preventDefault());
  document.addEventListener('keydown', e => {
    if (
      (e.ctrlKey && (e.key === 'c' || e.key === 'x' || e.key === 's' || e.key === 'u')) ||
      (e.metaKey && (e.key === 'c' || e.key === 'x' || e.key === 's' || e.key === 'u')) ||
      (e.ctrlKey && e.shiftKey && e.key === 'I') ||
      (e.ctrlKey && e.shiftKey && e.key === 'J') ||
      (e.ctrlKey && e.key === 'p')
    ) {
      e.preventDefault();
    }
  });
  document.body.style.userSelect = 'none';
</script>

</body>
</html>
