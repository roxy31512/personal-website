<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>The Current State of International AI Safety Cooperation | Roxana Akhmetova</title>
  <meta name="description" content="Overview of international cooperation on AI safety, multilateral initiatives, and challenges between major powers in frontier AI governance.">
  <meta name="keywords" content="International Cooperation, AI Safety, Governance, Diplomacy, AI Policy">
  <meta name="author" content="Roxana Akhmetova">

  <script src="https://cdn.tailwindcss.com"></script>
  <script>
    tailwind.config = {
      theme: {
        extend: {
          colors: {
            dark: '#1a1a1a',
            mid: '#4d4d4d',
            light: '#f7f7f8',
            oxford: '#002147',
            'oxford-100': '#e6eefb',
            'oxford-600': '#234e85'
          }
        }
      }
    }
  </script>

  <link rel="stylesheet" href="/style.css">

  <style>
    html, body {
      background-color: #1a1a1a !important;
      min-height: 100%;
      color: #ffffff;
    }

    main {
      margin-top: 100px;
      max-width: 900px;
      padding: 0 40px;
      margin-left: auto;
      margin-right: auto;
      margin-bottom: 80px;
    }

    h1 {
      font-size: 2.2rem !important;
      margin-bottom: 24px !important;
      color: #ffffff !important;
      font-weight: 600 !important;
      border-bottom: 3px solid #e6eefb;
      display: inline-block;
      padding-bottom: 8px;
    }

    .post-date {
      color: #9fc0ff;
      font-size: 0.95rem;
      margin-bottom: 30px;
      font-weight: 500;
    }

    .post-content p {
      color: #d8e1eb;
      font-size: 1.05rem;
      line-height: 1.8;
      margin-bottom: 20px;
    }

    .post-content strong {
      color: #ffffff;
    }

    .blog-post-tags {
      display: flex;
      gap: 10px;
      flex-wrap: wrap;
      margin-top: 30px;
    }

    .blog-tag {
      background: rgba(159, 192, 255, 0.1);
      color: #9fc0ff;
      padding: 5px 12px;
      border-radius: 15px;
      font-size: 0.85rem;
      font-weight: 500;
    }

    a.back-link {
      display: inline-block;
      color: #9fc0ff;
      margin-bottom: 40px;
      font-weight: 600;
      transition: all 0.3s ease;
    }

    a.back-link:hover {
      color: #ffffff;
      transform: translateX(-4px);
    }

    @media (max-width: 768px) {
      main { padding: 0 20px; }
      h1 { font-size: 1.8rem !important; }
      .post-content p { font-size: 1rem; }
    }
  </style>
</head>

<body>
  <custom-navbar></custom-navbar>

  <main>
    <a href="/blog.html" class="back-link">&larr; Back to Blog</a>

    <h1>The Current State of International AI Safety Cooperation</h1>
    <div class="post-date">October 28, 2025</div>

    <div class="post-content">
      <p>
        Over the past 5 years, international cooperation on AI safety has expanded significantly, 
        with several overlapping mechanisms that aimed to bring governments, corporations, 
        and civil society organisations together on the same page about how to safely build and deploy AI. 
        Despite the growing concern about risks from frontier AI, leading corporations and governments are 
        falling behind on ensuring that there are robust accountability, transparency, and fairness frameworks implemented.
      </p>

      <p>
        States organised a number of multilateral summits and talks in the past 5 years which brought together 
        governments, labs, and civil society to discuss frontier AI risks 
        (Bletchley Park 2023, Seoul 2024, Paris 2025, Delhi 2026). 
        One success is that Bletchley 2023 produced the Bletchley Declaration, signed by 28 countries, including the US and China. 
        This was a rare consensus on existential risks. 
        The Declaration also created AI Safety Institutes in the UK, US, Singapore, and Japan as national nodes for technical safety evaluation.
      </p>

      <p>
        But states aren't the only ones contributing to AI safety. 
        The UN AI Advisory Body and High-Level AI Governance Process have become key players. 
        The Secretary-General's advisory body released recommendations in 2024 for global AI governance 
        that pushed for creating an international scientific panel (IPCC-style) for AI risks. 
        A General Assembly resolution in March 2024 focused on “safe, secure and trustworthy AI” 
        and was the first global consensus document.
      </p>

      <p>
        Despite this, there are signs of cooperation. 
        For one, the US and the UK show strong collaboration through their AI Safety Institutes. 
        Both institutes share technical staff, collaborate on model evaluation frameworks, 
        and coordinate approaches to capability testing. 
        Their partnership works partly because both countries share similar regulatory philosophies 
        and neither sees the other as a strategic competitor in AI development.
      </p>

      <p>
        US and EU cooperation may be less optimistic due to differing governance approaches. 
        The US prioritises innovation and flexibility, 
        while the EU emphasises regulation-first frameworks. 
        The EU AI Act is a comprehensive model that influences global policy debates, 
        but it lacks strong enforcement mechanisms. 
        Conversely, the US is unlikely to adopt such an act because it may be seen as overly restrictive by AI developers.
      </p>

      <p>
        Given Chinese and American dominance in frontier AI, their cooperation faces the greatest tension. 
        Although there are some academic and informal dialogues, 
        government-level engagement remains constrained by geopolitical competition. 
        Tensions around export controls, national security, and technological supremacy 
        continue to shape AI diplomacy. 
        Both nations accelerate domestic AI development partly because each suspects the other 
        is further ahead in the race toward AGI, fueling a competitive dynamic that makes safety coordination necessary yet difficult.
      </p>

      <p>
        One limitation is that one of the most visible forms of coordination — export controls on advanced chips — 
        doesn’t prioritise safety over competition. 
        The US has restricted exports of H100 and H200 GPUs to China and coordinated with the Netherlands and Japan 
        to limit China’s access to semiconductor manufacturing equipment. 
        This fragments the global AI ecosystem. 
        Experts argue that treating AI development as a national security competition 
        while simultaneously trying to coordinate on safety thresholds is contradictory. 
        Countries cannot verify each other’s safety commitments when they view one another as strategic adversaries.
      </p>
    </div>

    <div class="blog-post-tags">
      <span class="blog-tag">International Cooperation</span>
      <span class="blog-tag">AI Safety</span>
      <span class="blog-tag">Governance</span>
      <span class="blog-tag">Diplomacy</span>
    </div>
  </main>

  <custom-footer></custom-footer>
  <script src="/components/navbar.js"></script>
  <script src="/components/footer.js"></script>

  <script>
    document.addEventListener('selectstart', e => e.preventDefault());
    document.addEventListener('contextmenu', e => e.preventDefault());
    document.addEventListener('keydown', e => {
      if (
        (e.ctrlKey && (e.key === 'c' || e.key === 'x' || e.key === 's' || e.key === 'u')) ||
        (e.metaKey && (e.key === 'c' || e.key === 'x' || e.key === 's' || e.key === 'u')) ||
        (e.ctrlKey && e.shiftKey && e.key === 'I') ||
        (e.ctrlKey && e.shiftKey && e.key === 'J') ||
        (e.ctrlKey && e.key === 'p')
      ) {
        e.preventDefault();
      }
    });
    document.body.style.userSelect = 'none';
  </script>
</body>
</html>
