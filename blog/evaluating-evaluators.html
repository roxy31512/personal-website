<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Who Evaluates the Evaluators? Frameworks for Accreditation in Frontier AI Governance | Roxana Akhmetova</title>
  <meta name="description" content="Who Evaluates the Evaluators? Frameworks for Accreditation in Frontier AI Governance" />
  <meta name="author" content="Roxana Akhmetova" />

  <script src="https://cdn.tailwindcss.com"></script>
  <script>
    tailwind.config = {
      theme: {
        extend: {
          colors: {
            dark: '#1a1a1a',
            mid: '#4d4d4d',
            light: '#f7f7f8',
            oxford: '#002147',
            'oxford-100': '#e6eefb',
            'oxford-600': '#234e85'
          }
        }
      }
    }
  </script>

  <link rel="stylesheet" href="/style.css" />

  <style>
    html, body {
      background-color: #1a1a1a !important;
      min-height: 100%;
      color: #ffffff;
    }

    main {
      margin-top: 100px;
      max-width: 900px;
      padding: 0 40px;
      margin-left: auto;
      margin-right: auto;
      margin-bottom: 80px;
    }

    h1 {
      font-size: 2.2rem !important;
      margin-bottom: 24px !important;
      color: #ffffff !important;
      font-weight: 600 !important;
      border-bottom: 3px solid #e6eefb;
      display: inline-block;
      padding-bottom: 8px;
    }

    .post-date {
      color: #9fc0ff;
      font-size: 0.95rem;
      margin-bottom: 30px;
      font-weight: 500;
    }

    .post-content p {
      color: #d8e1eb;
      font-size: 1.05rem;
      line-height: 1.8;
      margin-bottom: 20px;
    }

    .post-content strong {
      color: #ffffff;
      display: block;
      margin-top: 25px;
      margin-bottom: 8px;
      font-weight: 600;
    }

    .blog-post-tags {
      display: flex;
      gap: 10px;
      flex-wrap: wrap;
      margin-top: 30px;
    }

    .blog-tag {
      background: rgba(159, 192, 255, 0.1);
      color: #9fc0ff;
      padding: 5px 12px;
      border-radius: 15px;
      font-size: 0.85rem;
      font-weight: 500;
    }

    a.back-link {
      display: inline-block;
      color: #9fc0ff;
      margin-bottom: 40px;
      font-weight: 600;
      transition: all 0.3s ease;
    }

    a.back-link:hover {
      color: #ffffff;
      transform: translateX(-4px);
    }

    @media (max-width: 768px) {
      main { padding: 0 20px; }
      h1 { font-size: 1.8rem !important; }
      .post-content p { font-size: 1rem; }
    }
  </style>
</head>

<body>
  <custom-navbar></custom-navbar>

  <main>
    <a href="/blog.html" class="back-link">&larr; Back to Blog</a>

    <h1>Who Evaluates the Evaluators? Frameworks for Accreditation in Frontier AI Governance</h1>
    <div class="post-date">September 25, 2025</div>

    <div class="post-content">
      <p>A core challenge for accreditation is verifying an assessor's "independence from undue pressures", especially from the well-funded and influential AI developer being assessed. I propose a two-tiered system for ensuring and auditing this independence.</p>

      <strong>Tier 1:</strong>

      <p><strong>Pooled funding:</strong> To reduce the risk of AI developers influencing assessments, developers would pay into shared funds based on their AI model’s risk level; to reduce the risk of assessors picking clients themselves, accreditors would manage funding pools and compensate assessment firms via (algorithmic) randomisation.</p>

      <p><strong>Revenue diversification:</strong> To ensure independence, assessment firms would face revenue caps of no more than 8% from any developer ecosystem, including subsidiaries and major suppliers. 8% is stricter than typical audit standards for financial auditing, because of AI’s high market concentration in frontier AI. Senior assessment firm staff would not be allowed to be employed by assessed companies for 36 months, with mutual restrictions during ongoing evaluations.</p>

      <p><strong>Rotating networks:</strong> Accredited firms would occasionally reshuffle assessors to maintain assessors’ objectivity and autonomy preventing the same person/team from constantly assessing the same AI developer.</p>

      <p><strong>Tamper-evident documentation:</strong> To ensure a transparent and verifiable audit trail, accreditors would keep records by tracking developer-assessor interactions, methodology choices, and decisions. This also deters behind-the-scenes pressure tactics, as both parties know that all communication is subject to later audits.</p>

      <strong>Tier 2:</strong>

      <p><strong>Multi-modal verification:</strong> To detect potential compromise, independent teams would re-evaluate a random 15% of all assessments for warning signs such as unusually favorable outcomes, suspicious timing correlations, or systematic outlier patterns. To catch systematic bias, assessments that show a 20% variance from peer norms would automatically trigger an investigation.</p>

      <p><strong>Process analysis:</strong> To identify undue influence, investigators would examine communication patterns, decision timelines, and methodology deviations during formal reviews. To ensure thoroughness, investigators should focus specifically on developer pressure tactics and assessment manipulation attempts.</p>

      <p><strong>Cross-reference validation:</strong> To catch systematic under-assessment, the accreditation body would verify conclusions against a variety of independent indicators, including academic benchmarks and red-team results. To ensure thorough validation, they would cross-check findings with incident reports and real-world deployment outcomes.</p>

      <p><strong>Graduated enforcement:</strong> To maintain credible deterrence, an accreditation body would escalate sanctions from corrections and fines to suspension and debarment in severe cases. To address developer misconduct, their pressure tactics would result in pool exclusion and regulatory notification.</p>

      <p>Both tiers are important because they create complementary defense mechanisms against AI developer influence. The ex-ante mechanisms outlined above are aimed at making corruption structurally difficult while ex-post mechanisms are designed to catch sophisticated evasion attempts. Overall, this framework is designed to enable institutional learning. Prevention, detection, and adaptation can help ensure the system remains dynamic and effective.</p>
    </div>

    <div class="blog-post-tags">
      <span class="blog-tag">Accreditation</span>
      <span class="blog-tag">AI Governance</span>
      <span class="blog-tag">Audit</span>
      <span class="blog-tag">Policy</span>
    </div>
  </main>

  <custom-footer></custom-footer>
  <script src="/components/navbar.js"></script>
  <script src="/components/footer.js"></script>

<script>
  document.addEventListener('selectstart', e => e.preventDefault());
  document.addEventListener('contextmenu', e => e.preventDefault());
  document.addEventListener('keydown', e => {
    if (
      (e.ctrlKey && (e.key === 'c' || e.key === 'x' || e.key === 's' || e.key === 'u')) ||
      (e.metaKey && (e.key === 'c' || e.key === 'x' || e.key === 's' || e.key === 'u')) ||
      (e.ctrlKey && e.shiftKey && e.key === 'I') ||
      (e.ctrlKey && e.shiftKey && e.key === 'J') ||
      (e.ctrlKey && e.key === 'p')
    ) {
      e.preventDefault();
    }
  });
  document.body.style.userSelect = 'none';
</script>

</body>
</html>
